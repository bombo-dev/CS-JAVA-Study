### 캐시메모리 및 메모리 계층성에 대해서 설명해주세요.

* **캐시 메모리는 속도가 빠른 장치와 느린 장치간의 속도차에 따른 병목현상을 줄이기 위한 메모리**입니다. 기존의 캐시메모리는 CPU와 메모리 사이에 위치했으나, 현재 대부분의 L1, L2 캐시는 CPU 내부에 존재하고, L3 캐시만 메인보드에 위치하는데, 최근에는 L1, L2, L3 캐시도 모두 CPU 내부에 위치하고 있습니다.

* 메모리 계층성은 레지스터, 캐시, 메인 메모리, 보조기억장치로 분류하며, 레지스터가 최상층, 보조기억장치가 최하층에 위치하고 있습니다. 최상층에 가까울수록 사용 빈도가 잦고, 속도가 빠르며, 가격은 비싸고, 용량은 적습니다. 최하층은 그와 반대입니다.

  #### Q) L1, L2, L3 캐시 메모리에 대해서 설명해주세요.
  [!image](https://blog.kakaocdn.net/dn/lQYfE/btqzC3IIUQW/B8ctchIdwEZndxSYFlhkI0/img.png)   
    - 캐시를 분류하면 L1, L2, L3 캐시로 분류할 수 있는데 L1은 CPU 의 각 코어와 밀접하게 위치해있으며, L2 캐시는 CPU 내부에 위치해서 L1 캐시를 공유합니다. 마지막으로 L3가 메인보드에 위치하여 CPU와 메모리 사이에 위치해있습니다. 최근에는 L3 캐시도 CPU 안에 내장되있는 경우가 많습니다. L1에서 L3로 이동할 수록 속도가 상대적으로 느리고, 용량이 더 큽니다. 따라서 캐시메모리를 탐색할 때 L1 -> L2 -> L3 순서로 탐색을 합니다.
    #### Q) L1, L2, L3 캐시 메모리는 CPU 내부 어디에 위치하나요?
      - L1 캐시는 코어에 가장 가깝게 위치해있습니다. L1은 추가적으로 명령어 캐시(Instruction Cache), 데이터 캐시(Data Cache)로 나눌 수 있습니다.
      - L2 캐시는 L1보다는 코어에 덜 가깝게 위치해있습니다.
      - L3 캐시는 i5 이전에는 CPU 외부인 메인보드에 위치해있었는데, 최근에 등장하는 CPU는 L3 캐시가 CPU 내부로 들어와있습니다.

  #### Q) 메모리 계층을 분류한 이유와 이점에 대해서 설명해주세요.
    - 컴퓨터의 설계에 있어, 각각의 특징이 있는 서로 다른 여러 종류의 기억 장치를 함께 사용하여 최적의 효율을 낼 수 있게 하는 것. 빠른 저장 장치는 용량에 비해 가격이 비싸고, 용량이 넉넉한 저장 장치는 처리 속도가 느립니다. 그러나 컴퓨터가 행하는 작업은 매우 다양하고, 빠른 속도가 필요한 상황도 있지만 단순히 많은 내용을 천천히 읽고 쓰는 작업도 그만큼 많습니다. 이렇듯 상황에 맞게 여러 저장 장치를 각각 목적에 맞게 사용할 수 있도록 하여 싸고 성능 좋은 컴퓨터를 구현하는 설계하기 위해 메모리 계층을 분류하였습니다.

  #### Q) 캐시는 데이터를 어떻게 관리하는지 설명해주세요.
    - 캐시는 임시 데이터입니다. 따라서 원본 데이터의 내용이 바뀌면 캐시 또한 데이터가 바뀌어야 하는데, 임시 데이터이기 때문에 원본 데이터가 바뀌었다고 해서 바로 업데이트 되지 않습ㄴ다. 따라서, 캐시를 저장할 때 만료되는 시간인 TTL을 명시해서 캐시는 해당 시간 내에서만 유효하고 만료 시간이 경과하면 사용할 수 없도록 하고 있습니다. 그러나, 만료 시간 외에도 캐시의 유효성을 확인할 수 있는 방법이 2가지가 더 있습니다.

    1. 캐시가 사용될 때마다, 원본 데이터가 업데이트 된 시간과 캐시가 생성된 시간을 비교하여 캐시의 유효성을 판별하는 방식입니다. 단, 이 방법은 캐시가 사용될때마다 추가적으로 확인하는 절차가 필요하여 오버헤드가 발생합니다.

    2. 데이터가 수정이 되는 코드가 수행될 때마다 해당 데이터와 연관된 캐시를 무력화시키는 방법입니다. 캐시를 세밀하게 관리가 가능하여 이상적으로 설계되었을 때 가장 좋은 효율을 발휘합니다. 단, 코드로 캐시를 관리하기 때문에 에러가 발생하기 쉽고 관리가 어렵습니다.
    > Redis의 캐시 전략 4가지
    - Redis는 Read-Through(Lazy-Loading), Write-Through, Cache-Aside, Write-Back 총 4가지의 캐시 전략이 있습니다.
      1. Cache-Aside : 데이터를 찾을 때 캐시에 저장된 데이터가 있는지 우선적으로 확인하는 전략입니다. 이때 캐시 미스가 발생하면 DB 에서 조회합니다. 캐시와 DB가 분리되어 가용돼서 원하는 데이터만 별도로 구성하여 캐시에 저장이 가능하기 때문에 반복적인 읽기가 많은 호출에 적합하고, Read-Through에 비해서 캐시 장애 대비 구성이 되어있습니다. 하지만, 데이터 정합성 문제가 발생할 수 있습니다. 
      2. Read-Through : 캐시에서만 데이터를 읽어오는 전략입니다. 데이터 동기화를 라이브러리나 캐시 제공자에게 위임합니다. 캐시에서만 데이터를 불러오기 때문에 캐시와 DB간의 데이터 동기화가 항상 이루어져서 데이터 정합성 문제는 없으나 속도가 느리다는 단점이 있습니다. 또한, Redis가 다운 될 경우 서비스 이용에 제한이 생깁니다.
      3. Write-Through : 데이터베이스와 Cache에 동시에 데이터를 저장하는 전략입니다. 데이터를 저장할 때 먼저 캐시에 저장한 다음 바로 DB에 저장하기 때문에 캐시의 데이터는 항상 최신 상태로 유지될 수 있습니다. 하지만 자주 사용되지 않는 불필요한 요소들도 저장을 하고 매 요청시마다 두번의 Write 발생으로 인해 성능 저하가 발생합니다. 따라서 데이터 유실이 절대로 발생하면 안되는 상황에 적합합니다.
      4. Write-Back : 캐시와 DB 동기화를 비동기적으로 수행합니다. 데이터를 저장할 때 DB에 바로 저장하지 않고, 캐시가 마치 Queue 처럼 동작하여 캐시에 모았다가 일정 주기에 DB에 반영합니다. 따라서 Write-Through에 비해서 쓰기 쿼리 회수 비용과 부하를 줄일 수 있습니다. 따라서, Write가 많을 경우에 사용하는 것이 좋습니다. 하지만 캐시에 데이터가 모아진 상태에서 캐시에서 오류가 발생하면 해당 데이터를 소실할 수 있다는 문제점이 있습니다.
      5. Write-Around : 캐시 미스가 발생할 경우에만 캐시에도 데이터를 저장하고, 그 외에 경우에는 모든 데이터를 DB에 저장합니다. Write-Through 보다 훨씬 빠르지만, 데이터의 정합성이 지켜지지 않는다는 문제가 있습니다.

  #### Q) 캐시의 지역성에 대해서 설명해주세요.
    - 캐시는 참조 지역성의 원리에 근거해서 데이터를 저장합니다.  
    참조 지역성의 원리는 시간 지역성, 공간 지역성, 순차 지역성 세 가지로 분류할 수 있는데, 이 때 순차 지역성은 공간 지역성과 비슷하여 보통 시간 지역성, 공간 지역성 두 가지로 분류합니다.
    - 시간 지역성은 최근 사용했던 메모리를 빠른 시간 안에 참조한다는 개념이고, 공간 지역성은 참조된 메모리 근처의 메모리를 참조한다는 개념입니다. 
  
  #### Q) 캐시의 지역성을 기반으로, 이차원 배열을 탐색했을 때의 성능 차이에 대해서 설명해주세요.
    - 한 배열 내에서 가로로 접근하게 되면 하나의 배열의 근접한 메모리의 주소를 캐시의 메모리 만큼 바로 탐색이 가능하여 공간 지역성에 대한 장점을 활용할 수 있습니다. 그러나 세로로 탐색을 하게 되면 인접한 요소가 아닌, 다른 새로운 배열의 요소에 탐색을 하기 때문에, 가로로 탐색하는 것에 비해 좋지 않은 공간 지역성을 가진 것이라고 볼 수 있습니다.
  
  > L1 캐시는 세부적인 영역으로 추가적으로 나누어지는데, 이에 대해서 설명해주세요.
    - L1 캐시는 코어와 가장 밀접해있는 캐시입니다. 주로 명령어나 데이터를 다룰 때 사용을 하게 되는데, 이러한 명령어나 데이터도 주소 버스와 데이터 버스를 통해서 이동을 해야하는 과정을 거치게 되면 시간 지연이 발생해서 자주 사용하는 명령어와 데이터는 L1 캐시에 적재를 하게 되는데, 이 때, 이 캐시의 속도를 더 향상 시키기 위해 Instruction Cache와 Data Cache로 나누고 있습니다.

  #### Q) 캐시 메모리와 메인 메모리의 매핑 방식에 대해서 설명해주세요.
    - 캐시 메모리는 메인 메모리에 비해서 용량이 작아서 1:1로 매핑이 불가능합니다. 이에 따라 특정 자료구조를 이용하여 캐시 메모리에 저장하는데, 이러한 저장 방식을 캐싱 라인이라고 합니다. 그리고 이 캐싱 라인은 3가지 방법이 있습니다.
      1. 직접 매핑
          - 메인 메모리를 일정한 크기의 블록으로 나누고 블록 크기 word에 따라 캐시의 정해진 위치에 매핑하는 방식입니다.
          - 캐시 메모리의 각 구역에 지역성의 원리에 위배 된 여러 개의 데이터들이 같이 담길 수 있어서, 캐시 히트 비율이 떨어집니다.
      2. 연관 매핑
          - 캐시 메모리에 빈 공간에 마음대로 주소를 저장하는 방식입니다.
          - 실제로 자주 사용되는 데이터들만 캐시 메모리에 적재를 하기 때문에, 캐시 히트 비율은 높아지나, 캐시 메모리에 담긴 데이터를 찾을 때 모든 태그를 병렬적으로 검사해야해서, 복잡하고 비용이 많이 발생합니다.
      3. 세트 연관 매핑
          - 직접 매핑의 장점과 연관 매핑의 장점을 합친 기법입니다.
          - 블럭 단위로 나누고, 빈 공간에 마음대로 저장을 합니다. 이때, 세트 당 캐시 라인의 수에 따라 m-way-set 연관 매핑이라고 합니다.
          - 세트 연관 매핑에서 m을 1로 두면, 이는 직접 연관 매핑이 됩니다. 또, 세트 수를 캐시 라인 수와 동일하게 두면 이는 연관 매핑이 됩니다.

  #### Q) 캐시 동기화에 대해서 설명해주세요.
    - 캐시의 동기화 방식은 크게 3가지로 구분할 수 있습니다.
        1. 캐시가 사용될 때마다, 원본 데이터가 업데이트 된 시간과 캐시가 생성된 시간을 비교하여 캐시의 유효성을 판별하는 방식입니다. 단, 이 방법은 캐시가 사용될때마다 추가적으로 확인하는 절차가 필요하여 오버헤드가 발생합니다.
        2. 데이터가 수정이 되는 코드가 수행될 때마다 해당 데이터와 연관된 캐시를 업데이트시키는 방법입니다. 캐시를 세밀하게 관리가 가능하여 이상적으로 설계되었을 때 가장 좋은 효율을 발휘합니다. 단, 코드로 캐시를 관리하기 때문에 에러가 발생하기 쉽고 관리가 어렵습니다.

    - 캐시 동기화는 캐시 쓰기 요청이 어떤 목적이냐에 따라 다릅니다. 크게 3가지로 구분 할 수 있습니다.
      1. Write Around
          - 쓰기 작업 중에 캐시는 건들지 않고, 읽기 작업 시에 Cache Miss가 발생하면 업데이트 됩니다.  
      2. Write Through
          - 쓰기 작업 시 캐시를 동기화 한 이후에, 데이터를 반환합니다. 따라서, 캐시를 항상 최신 상태를 유지할 수 있지만, 동기식으로 갱신한 이후 최종 데이터 반환이 되기 때문에 속도 면에서 성능이 떨어질 수 있습니다.
      3. Write Back
          - 동기화 작업을 비동기로 하는 방법입니다. 쓰기 작업이 매우 많은 경우에 택하는 방법이고, 일정량의 데이터를 모아놓았다가 한 번에 업데이트합니다. 그러나, 구현이 복잡하고, 일정량의 데이터가 모아져 있는 상태에서 장애가 발생하면 데이터가 유실될 수 있는 문제가 있습니다. 

  #### 사진, 내용에 대한 출처
  - https://bcp0109.tistory.com/364
  - https://inpa.tistory.com/entry/REDIS-%F0%9F%93%9A-%EC%BA%90%EC%8B%9CCache-%EC%84%A4%EA%B3%84-%EC%A0%84%EB%9E%B5-%EC%A7%80%EC%B9%A8-%EC%B4%9D%EC%A0%95%EB%A6%AC
  - https://rebro.kr/180